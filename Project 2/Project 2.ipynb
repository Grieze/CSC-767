{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1332/1332 [00:31<00:00, 41.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1867/1867 [00:45<00:00, 41.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1387/1387 [00:36<00:00, 37.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1334/1334 [00:29<00:00, 45.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1424/1424 [00:31<00:00, 45.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1186/1186 [00:30<00:00, 38.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob,os\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Using and loading the same dataset from project 1\n",
    "DATADIR = \"C:\\\\Users\\\\Aaron\\\\Documents\\\\data\\\\planes\\\\\"\n",
    "\n",
    "CATEGORIES = [\"drone\", \"fighter-jet\", \"helicopter\", \"missile\", \"passenger-plane\", \"rocket\"]\n",
    "\n",
    "img_array = []\n",
    "\n",
    "for category in CATEGORIES:  # do all categories\n",
    "    path = os.path.join(DATADIR,category)  # create path to each category\n",
    "    for img in os.listdir(path):  # iterate over each image per each category\n",
    "        img_array.append(cv2.imread(os.path.join(path,img)))  # convert to array\n",
    "        \n",
    "path = 'C:\\\\Users\\\\Aaron\\\\Documents\\\\data\\\\planes\\\\'\n",
    "files = [f for f in glob.glob(path + \"*/*.jpeg\", recursive=True)]\n",
    "\n",
    "training_data = []\n",
    "IMG_SIZE = 299\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do all 6 categories\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to all 6 classes\n",
    "        class_num = CATEGORIES.index(category)  # get the classification number for each class\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per category\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "                data_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([data_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# shuffle our training data\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])\n",
    "# Just a quick peek on our shuffled data\n",
    "# The reason we do this is so that our algorithm can properly learn the images, if they were sequential the \n",
    "# the model would get easily confused and have incorrect weights and might not reach optimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X = X/255.0\n",
    "\n",
    "# Split the data into train, valid, and test sets into 70-20-10 split , X_valid, X_test \n",
    "X_train, y_train = X[0:6000], y[0:6000]\n",
    "X_valid, y_valid = X[6000:7800], y[6000:7800]\n",
    "X_test, y_test = X[7800:8510], y[7800:8510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Inception-ResNet-V2\n",
    "InceptionResNetV2 = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=\"max\",\n",
    "    classes=6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling Inception-ResNet-V2\n",
    "InceptionResNetV2.compile(optimizer = \"adam\", loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiting the model and testing its performance\n",
    "InceptionResNetV2_history = InceptionResNetV2.fit(X_train, y_train, epochs = 40, batch_size = 128,\n",
    "                                                   verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Inception-V4\n",
    "import numpy as np\n",
    "\n",
    "# Sys\n",
    "import warnings\n",
    "# Keras Core\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "# Backend\n",
    "from keras import backend as K\n",
    "# Utils\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Implements the Inception Network v4 (http://arxiv.org/pdf/1602.07261v1.pdf) in Keras. #\n",
    "#########################################################################################\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/kentsommer/keras-inceptionV4/releases/download/2.1/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x = np.divide(x, 255.0)\n",
    "    x = np.subtract(x, 0.5)\n",
    "    x = np.multiply(x, 2.0)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
    "              padding='same', strides=(1, 1), use_bias=False):\n",
    "    \"\"\"\n",
    "    Utility function to apply conv + BN. \n",
    "    (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "    x = Convolution2D(nb_filter, (num_row, num_col),\n",
    "                      strides=strides,\n",
    "                      padding=padding,\n",
    "                      use_bias=use_bias,\n",
    "                      kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 96, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 64, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3, 3)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 96, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_a(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 3, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 384, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 224, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 7, 1)\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 192, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 1, 7)\n",
    "    branch_2 = conv2d_bn(branch_2, 224, 7, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 1, 7)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 128, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_reduction_b(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 192, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 256, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 320, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(input)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block_inception_c(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    branch_0 = conv2d_bn(input, 256, 1, 1)\n",
    "\n",
    "    branch_1 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_10 = conv2d_bn(branch_1, 256, 1, 3)\n",
    "    branch_11 = conv2d_bn(branch_1, 256, 3, 1)\n",
    "    branch_1 = concatenate([branch_10, branch_11], axis=channel_axis)\n",
    "\n",
    "\n",
    "    branch_2 = conv2d_bn(input, 384, 1, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 448, 3, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 512, 1, 3)\n",
    "    branch_20 = conv2d_bn(branch_2, 256, 1, 3)\n",
    "    branch_21 = conv2d_bn(branch_2, 256, 3, 1)\n",
    "    branch_2 = concatenate([branch_20, branch_21], axis=channel_axis)\n",
    "\n",
    "    branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "    branch_3 = conv2d_bn(branch_3, 256, 1, 1)\n",
    "\n",
    "    x = concatenate([branch_0, branch_1, branch_2, branch_3], axis=channel_axis)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_v4_base(input):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (th) or 3 x 299 x 299 (th)\n",
    "    net = conv2d_bn(input, 32, 3, 3, strides=(2,2), padding='valid')\n",
    "    net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
    "    net = conv2d_bn(net, 64, 3, 3)\n",
    "\n",
    "    branch_0 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 96, 3, 3, strides=(2,2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 96, 3, 3, padding='valid')\n",
    "\n",
    "    branch_1 = conv2d_bn(net, 64, 1, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 1, 7)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 7, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 96, 3, 3, padding='valid')\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    branch_0 = conv2d_bn(net, 192, 3, 3, strides=(2,2), padding='valid')\n",
    "    branch_1 = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_0, branch_1], axis=channel_axis)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # 4 x Inception-A blocks\n",
    "    for idx in range(4):\n",
    "    \tnet = block_inception_a(net)\n",
    "\n",
    "    # 35 x 35 x 384\n",
    "    # Reduction-A block\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # 7 x Inception-B blocks\n",
    "    for idx in range(7):\n",
    "    \tnet = block_inception_b(net)\n",
    "\n",
    "    # 17 x 17 x 1024\n",
    "    # Reduction-B block\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 8 x 8 x 1536\n",
    "    # 3 x Inception-C blocks\n",
    "    for idx in range(3):\n",
    "    \tnet = block_inception_c(net)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def inception_v4(num_classes, dropout_keep_prob, weights, include_top):\n",
    "    '''\n",
    "    Creates the inception v4 network\n",
    "    Args:\n",
    "    \tnum_classes: number of classes\n",
    "    \tdropout_keep_prob: float, the fraction to keep before final layer.\n",
    "    \n",
    "    Returns: \n",
    "    \tlogits: the logits outputs of the model.\n",
    "    '''\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputs = Input((3, 299, 299))\n",
    "    else:\n",
    "        inputs = Input((299, 299, 3))\n",
    "\n",
    "    # Make inception base\n",
    "    x = inception_v4_base(inputs)\n",
    "\n",
    "\n",
    "    # Final pooling and prediction\n",
    "    if include_top:\n",
    "        # 1 x 1 x 1536\n",
    "        x = AveragePooling2D((8,8), padding='valid')(x)\n",
    "        x = Dropout(dropout_keep_prob)(x)\n",
    "        x = Flatten()(x)\n",
    "        # 1536\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='inception_v4')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9fe79d77f793fe874470d84ca6ba4a3b')\n",
    "        else:\n",
    "            weights_path = get_file(\n",
    "                'inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9296b46b5971573064d12e4669110969')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(num_classes=1001, dropout_prob=0.2, weights=None, include_top=True):\n",
    "    return inception_v4(num_classes, dropout_prob, weights, include_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the actual model\n",
    "inception_v4_model = create_model(num_classes=6, dropout_prob=0.2, weights=None, include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling it using adam as the optimizer\n",
    "inception_v4_model.compile(optimizer = \"adam\", loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                          metrics=['accuracy'])              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiting the model and testing its performance\n",
    "inception_v4_model_history = inception_v4_model.fit(X_train, y_train, epochs = 40, batch_size = 128,\n",
    "                                                   verbose=1, validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
